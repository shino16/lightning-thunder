I0914 01:47:57.064000 112965 torch/_inductor/config.py:820] compile_threads set to 32
/opt/pytorch/nvfuser/python/nvfuser_direct/__init__.py:11: UserWarning: Be careful! You've imported nvfuser_direct when the nvfuser module is already imported.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/transformer_engine/__init__.py:59: RuntimeWarning: Detected a Jax installation but could not find the shared object file for the Transformer Engine Jax extension library. If this is not intentional, please reinstall Transformer Engine with `pip install transformer_engine[jax]` or build from source with `NVTE_FRAMEWORK=jax`.
  warnings.warn(
/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1605: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /opt/pytorch/pytorch/aten/src/ATen/Context.cpp:80.)
  _C._set_float32_matmul_precision(precision)
V0914 01:48:01.528000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:74 in forward (GPT.forward)
V0914 01:48:01.528000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, idx: torch.Tensor, input_pos: Optional[torch.Tensor] = None) -> torch.Tensor:
V0914 01:48:01.537000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:75 in forward (GPT.forward)
V0914 01:48:01.537000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             T = idx.size(1)
V0914 01:48:01.541000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:76 in forward (GPT.forward)
V0914 01:48:01.541000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.max_seq_length < T:
V0914 01:48:01.543000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:36 in max_seq_length (GPT) (inline depth: 1)
V0914 01:48:01.543000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         @property
V0914 01:48:01.543000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:38 in max_seq_length (GPT.max_seq_length) (inline depth: 1)
V0914 01:48:01.543000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return self._max_seq_length
V0914 01:48:01.544000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:79 in forward (GPT.forward)
V0914 01:48:01.544000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if input_pos is not None:  # use the kv cache
V0914 01:48:01.544000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:90 in forward (GPT.forward)
V0914 01:48:01.544000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 cos = self.cos[:T]
V0914 01:48:01.548000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:91 in forward (GPT.forward)
V0914 01:48:01.548000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 sin = self.sin[:T]
V0914 01:48:01.550000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:92 in forward (GPT.forward)
V0914 01:48:01.550000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 mask = None
V0914 01:48:01.550000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:94 in forward (GPT.forward)
V0914 01:48:01.550000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = self.transformer.wte(idx)  # token embeddings of shape (b, t, n_embd)
V0914 01:48:01.553000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:191 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.553000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:01.555000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:192 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.555000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.embedding(
V0914 01:48:01.556000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:193 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.556000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 input,
V0914 01:48:01.556000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:194 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.556000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 self.weight,
V0914 01:48:01.557000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:195 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.557000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 self.padding_idx,
V0914 01:48:01.558000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:196 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.558000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 self.max_norm,
V0914 01:48:01.558000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:197 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.558000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 self.norm_type,
V0914 01:48:01.559000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:198 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.559000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 self.scale_grad_by_freq,
V0914 01:48:01.559000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:199 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.559000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 self.sparse,
V0914 01:48:01.559000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/sparse.py:192 in forward (Embedding.forward) (inline depth: 1)
V0914 01:48:01.559000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.embedding(
V0914 01:48:01.567000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:95 in forward (GPT.forward)
V0914 01:48:01.567000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.config.scale_embeddings:
V0914 01:48:01.567000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:96 in forward (GPT.forward)
V0914 01:48:01.567000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 x = x * torch.tensor(self.config.n_embd**0.5, dtype=x.dtype)
V0914 01:48:01.571000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:98 in forward (GPT.forward)
V0914 01:48:01.571000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             for block in self.transformer.h:
V0914 01:48:01.572000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py:403 in __iter__ (Sequential.__init__.__init__.ModuleList.__getitem__.__getitem__) (inline depth: 1)
V0914 01:48:01.572000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         @_copy_to_script_wrapper
V0914 01:48:01.579000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py:405 in __iter__ (Sequential.__init__.__init__.ModuleList.__getitem__.__getitem__.__iter__) (inline depth: 1)
V0914 01:48:01.579000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return iter(self._modules.values())
V0914 01:48:01.580000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py:403 in __iter__ (Sequential.__init__.__init__.ModuleList.__getitem__.__getitem__) (inline depth: 1)
V0914 01:48:01.580000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         @_copy_to_script_wrapper
V0914 01:48:01.580000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py:405 in __iter__ (Sequential.__init__.__init__.ModuleList.__getitem__.__getitem__.__iter__) (inline depth: 1)
V0914 01:48:01.580000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return iter(self._modules.values())
V0914 01:48:01.581000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:99 in forward (GPT.forward)
V0914 01:48:01.581000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 x = block(x, cos, sin, mask, input_pos)
V0914 01:48:01.582000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:145 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.582000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, *args, **kwargs):
V0914 01:48:01.584000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:149 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.584000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.checkpoint_impl == CheckpointImpl.REENTRANT and kwargs != {}:
V0914 01:48:01.585000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py:352 in cmp_eq (cmp_eq) (inline depth: 2)
V0914 01:48:01.585000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def cmp_eq(a, b):
V0914 01:48:01.588000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py:361 in cmp_eq (cmp_eq) (inline depth: 2)
V0914 01:48:01.588000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         result = a.__eq__(b)
V0914 01:48:01.589000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py:362 in cmp_eq (cmp_eq) (inline depth: 2)
V0914 01:48:01.589000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if result is NotImplemented:
V0914 01:48:01.589000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py:364 in cmp_eq (cmp_eq) (inline depth: 2)
V0914 01:48:01.589000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return result is not NotImplemented and result
V0914 01:48:01.590000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.590000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:01.590000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:172 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.590000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     self._checkpoint_wrapped_module, *args, **kwargs
V0914 01:48:01.591000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:46 in __getattr__ (ActivationWrapper.__getattr__) (inline depth: 2)
V0914 01:48:01.591000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def __getattr__(self, name: str) -> Any:
V0914 01:48:01.591000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:48 in __getattr__ (ActivationWrapper.__getattr__) (inline depth: 2)
V0914 01:48:01.591000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             try:
V0914 01:48:01.591000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:49 in __getattr__ (ActivationWrapper.__getattr__) (inline depth: 2)
V0914 01:48:01.591000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return super().__getattr__(name)  # defer to nn.Module's logic
V0914 01:48:01.593000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1951 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.593000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def __getattr__(self, name: str) -> Union[Tensor, "Module"]:
V0914 01:48:01.608000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1952 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.608000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if "_parameters" in self.__dict__:
V0914 01:48:01.610000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1953 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.610000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 _parameters = self.__dict__["_parameters"]
V0914 01:48:01.611000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1954 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.611000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if name in _parameters:
V0914 01:48:01.612000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1956 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.612000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if "_buffers" in self.__dict__:
V0914 01:48:01.614000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1957 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.614000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 _buffers = self.__dict__["_buffers"]
V0914 01:48:01.615000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1958 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.615000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if name in _buffers:
V0914 01:48:01.616000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1960 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.616000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if "_modules" in self.__dict__:
V0914 01:48:01.617000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1961 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.617000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 modules = self.__dict__["_modules"]
V0914 01:48:01.619000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1962 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.619000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if name in modules:
V0914 01:48:01.621000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1963 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.621000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     return modules[name]
V0914 01:48:01.622000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.622000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:01.623000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:172 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.623000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     self._checkpoint_wrapped_module, *args, **kwargs
V0914 01:48:01.623000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.623000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:01.624000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:172 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.624000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     self._checkpoint_wrapped_module, *args, **kwargs
V0914 01:48:01.624000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.624000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:01.626000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:199 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.626000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(
V0914 01:48:01.627000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:228 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.627000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = self.norm_1(x)
V0914 01:48:01.629000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.629000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:01.630000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.630000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:01.631000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.631000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:01.635000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.635000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:01.640000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.640000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:01.646000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.646000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:01.650000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.650000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:01.655000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:229 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.655000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             attention_output = self.attn(x_normed, cos, sin, mask, input_pos)
V0914 01:48:01.658000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:259 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.658000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(
V0914 01:48:01.659000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:267 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.659000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             B, T, C = x.size()  # batch size, sequence length, embedding dimensionality (n_embd)
V0914 01:48:01.660000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:269 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.660000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             qkv = self.attn(x)
V0914 01:48:01.663000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.663000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:01.665000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.665000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:01.671000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:272 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.671000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q_per_kv = self.config.n_head // self.config.n_query_groups
V0914 01:48:01.673000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:273 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.673000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             total_qkv = q_per_kv + 2  # each group has 1+ queries, 1 key, and 1 value
V0914 01:48:01.674000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:274 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.674000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             qkv = qkv.view(B, T, self.config.n_query_groups, total_qkv, self.config.head_size)
V0914 01:48:01.679000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:275 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.679000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             qkv = qkv.permute(0, 2, 3, 1, 4)  # (B, n_query_groups, total_qkv, T, hs)
V0914 01:48:01.681000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:278 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.681000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q, k, v = qkv.split((q_per_kv, 1, 1), dim=2)
V0914 01:48:01.684000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:283 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.684000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.config.n_query_groups != self.config.n_head and (input_pos is None or self.config.n_query_groups != 1):
V0914 01:48:01.686000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:284 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.686000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 k = k.expand(B, self.config.n_query_groups, q_per_kv, T, self.config.head_size)
V0914 01:48:01.689000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:285 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.689000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 v = v.expand(B, self.config.n_query_groups, q_per_kv, T, self.config.head_size)
V0914 01:48:01.692000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:287 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.692000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q = q.reshape(B, -1, T, self.config.head_size)  # (B, nh_q, T, hs)
V0914 01:48:01.696000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:288 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.696000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             k = k.reshape(B, -1, T, self.config.head_size)  # (B, nh_k, T, hs)
V0914 01:48:01.699000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:289 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.699000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             v = v.reshape(B, -1, T, self.config.head_size)  # (B, nh_v, T, hs)
V0914 01:48:01.702000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:291 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.702000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q_roped = apply_rope(q[..., : self.config.rope_n_elem], cos, sin)
V0914 01:48:01.706000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:579 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.706000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def apply_rope(x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:
V0914 01:48:01.707000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:580 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.707000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         head_size = x.size(-1)
V0914 01:48:01.707000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:581 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.707000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         x1 = x[..., : head_size // 2]  # (B, nh, T, hs/2)
V0914 01:48:01.709000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:582 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.709000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         x2 = x[..., head_size // 2 :]  # (B, nh, T, hs/2)
V0914 01:48:01.710000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:583 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.710000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         rotated = torch.cat((-x2, x1), dim=-1)  # (B, nh, T, hs)
V0914 01:48:01.714000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:584 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.714000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if cos.dim() > 1:
V0914 01:48:01.714000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:588 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.714000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             cos = cos.unsqueeze(-3)
V0914 01:48:01.716000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:589 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.716000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             sin = sin.unsqueeze(-3)
V0914 01:48:01.717000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:591 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.717000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         roped = (x * cos) + (rotated * sin)
V0914 01:48:01.720000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:592 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.720000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return roped.to(dtype=x.dtype)
V0914 01:48:01.721000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:292 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.721000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             k_roped = apply_rope(k[..., : self.config.rope_n_elem], cos, sin)
V0914 01:48:01.724000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:579 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.724000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def apply_rope(x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:
V0914 01:48:01.724000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:580 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.724000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         head_size = x.size(-1)
V0914 01:48:01.724000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:581 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.724000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         x1 = x[..., : head_size // 2]  # (B, nh, T, hs/2)
V0914 01:48:01.726000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:582 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.726000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         x2 = x[..., head_size // 2 :]  # (B, nh, T, hs/2)
V0914 01:48:01.727000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:583 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.727000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         rotated = torch.cat((-x2, x1), dim=-1)  # (B, nh, T, hs)
V0914 01:48:01.728000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:584 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.728000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if cos.dim() > 1:
V0914 01:48:01.729000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:588 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.729000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             cos = cos.unsqueeze(-3)
V0914 01:48:01.730000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:589 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.730000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             sin = sin.unsqueeze(-3)
V0914 01:48:01.731000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:591 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.731000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         roped = (x * cos) + (rotated * sin)
V0914 01:48:01.733000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:592 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:01.733000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return roped.to(dtype=x.dtype)
V0914 01:48:01.734000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:293 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.734000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q = torch.cat((q_roped, q[..., self.config.rope_n_elem :]), dim=-1)
V0914 01:48:01.737000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:294 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.737000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             k = torch.cat((k_roped, k[..., self.config.rope_n_elem :]), dim=-1)
V0914 01:48:01.741000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:296 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.741000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if input_pos is not None:
V0914 01:48:01.742000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:301 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.742000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.apply_sliding_window_attention:
V0914 01:48:01.743000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:302 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.743000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 """
V0914 01:48:01.744000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:312 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.744000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if mask is None:
V0914 01:48:01.745000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:313 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.745000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     mask = torch.ones(T, T, dtype=q.dtype, device=q.device).triu(diagonal=1)
V0914 01:48:01.750000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:314 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.750000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     mask.masked_fill_(mask.bool(), float("-inf"))
V0914 01:48:01.754000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:315 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.754000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 sliding_window_bias = torch.ones_like(mask).tril(diagonal=-self.config.sliding_window_size)
V0914 01:48:01.759000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:316 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.759000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 sliding_window_bias.masked_fill_(sliding_window_bias.bool(), float("-inf"))
V0914 01:48:01.761000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:317 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.761000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 mask += sliding_window_bias
V0914 01:48:01.763000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:319 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.763000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             y = self.scaled_dot_product_attention(q, k, v, mask)
V0914 01:48:01.766000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:326 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.766000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def scaled_dot_product_attention(
V0914 01:48:01.766000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:329 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.766000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             scale = 1.0 / math.sqrt(self.config.attention_scores_scalar or self.config.head_size)
V0914 01:48:01.768000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:332 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.768000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.config.attention_logit_softcapping is not None:
V0914 01:48:01.768000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:333 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.768000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scale = 1.0 / math.sqrt(self.config.attention_scores_scalar or self.config.head_size)
V0914 01:48:01.769000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:334 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.769000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scores = q @ k.mT * scale
V0914 01:48:01.777000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:336 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.777000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     torch.tanh(scores / self.config.attention_logit_softcapping) * self.config.attention_logit_softcapping
V0914 01:48:01.782000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:335 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.782000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scores = (
V0914 01:48:01.782000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:338 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.782000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if mask is None:
V0914 01:48:01.783000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:341 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.783000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scores = scores + mask
V0914 01:48:01.784000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:342 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.784000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scores = torch.nn.functional.softmax(scores, dim=-1, dtype=torch.float).to(dtype=q.dtype)
V0914 01:48:01.789000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:343 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.789000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 y = scores @ v
V0914 01:48:01.793000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:348 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:01.793000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return y.transpose(1, 2)
V0914 01:48:01.795000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:321 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.795000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             y = y.reshape(B, T, self.config.head_size * self.config.n_head)  # re-assemble all head outputs side by side
V0914 01:48:01.799000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:324 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.799000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return self.proj(y)
V0914 01:48:01.800000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.800000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:01.801000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.801000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:01.806000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:230 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.806000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             attention_output = self.post_attention_norm(attention_output)
V0914 01:48:01.807000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.807000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:01.808000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.808000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:01.809000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.809000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:01.811000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.811000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:01.814000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.814000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:01.817000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.817000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:01.820000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.820000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:01.824000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:232 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.824000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.config.parallel_residual:
V0914 01:48:01.824000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:236 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.824000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 x = attention_output + x
V0914 01:48:01.826000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:237 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.826000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 x = self.post_mlp_norm(self.mlp(self.norm_2(x))) + x
V0914 01:48:01.827000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.827000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:01.829000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.829000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:01.830000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.830000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:01.831000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.831000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:01.834000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.834000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:01.838000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.838000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:01.841000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.841000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:01.845000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:405 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:01.845000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:01.846000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:406 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:01.846000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_fc_1 = self.fc_1(x)
V0914 01:48:01.848000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.848000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:01.848000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.848000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:01.852000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:407 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:01.852000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_fc_2 = self.fc_2(x)
V0914 01:48:01.854000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.854000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:01.855000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.855000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:01.857000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:408 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:01.857000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = torch.nn.functional.gelu(x_fc_1, approximate=self.config.gelu_approximate) * x_fc_2
V0914 01:48:01.863000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:409 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:01.863000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return self.proj(x)
V0914 01:48:01.865000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.865000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:01.865000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.865000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:01.870000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.870000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:01.871000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.871000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:01.872000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.872000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:01.873000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.873000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:01.876000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.876000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:01.880000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.880000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:01.883000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.883000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:01.887000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:238 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.887000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return x
V0914 01:48:01.888000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1268 in tree_flatten (tree_flatten) (inline depth: 2)
V0914 01:48:01.888000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def tree_flatten(
V0914 01:48:01.902000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1276 in tree_flatten (tree_flatten.helper) (inline depth: 2)
V0914 01:48:01.902000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def helper(node: PyTree, leaves: list[Any]) -> TreeSpec:
V0914 01:48:01.903000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1289 in tree_flatten (tree_flatten) (inline depth: 2)
V0914 01:48:01.903000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         leaves: list[Any] = []
V0914 01:48:01.904000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1290 in tree_flatten (tree_flatten) (inline depth: 2)
V0914 01:48:01.904000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         treespec = helper(tree, leaves)
V0914 01:48:01.905000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1276 in helper (tree_flatten.helper) (inline depth: 3)
V0914 01:48:01.905000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def helper(node: PyTree, leaves: list[Any]) -> TreeSpec:
V0914 01:48:01.905000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1277 in helper (tree_flatten.helper) (inline depth: 3)
V0914 01:48:01.905000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if tree_is_leaf(node, is_leaf=is_leaf):
V0914 01:48:01.906000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1024 in tree_is_leaf (tree_is_leaf) (inline depth: 4)
V0914 01:48:01.906000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def tree_is_leaf(
V0914 01:48:01.907000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1043 in tree_is_leaf (tree_is_leaf) (inline depth: 4)
V0914 01:48:01.907000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if is_leaf is not None and is_leaf(tree):
V0914 01:48:01.907000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1045 in tree_is_leaf (tree_is_leaf) (inline depth: 4)
V0914 01:48:01.907000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return _get_node_type(tree) not in SUPPORTED_NODES
V0914 01:48:01.908000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1012 in _get_node_type (_get_node_type) (inline depth: 5)
V0914 01:48:01.908000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def _get_node_type(tree: Any) -> Any:
V0914 01:48:01.908000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1013 in _get_node_type (_get_node_type) (inline depth: 5)
V0914 01:48:01.908000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         node_type = type(tree)
V0914 01:48:01.909000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1018 in _get_node_type (_get_node_type) (inline depth: 5)
V0914 01:48:01.909000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if is_namedtuple_class(node_type):
V0914 01:48:01.910000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:679 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:01.910000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def is_namedtuple_class(cls: type) -> bool:
V0914 01:48:01.911000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:682 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:01.911000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             isinstance(cls, type)
V0914 01:48:01.911000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:683 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:01.911000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             and issubclass(cls, tuple)
V0914 01:48:01.912000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:682 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:01.912000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             isinstance(cls, type)
V0914 01:48:01.912000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:681 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:01.912000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return (
V0914 01:48:01.912000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1020 in _get_node_type (_get_node_type) (inline depth: 5)
V0914 01:48:01.912000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return node_type
V0914 01:48:01.915000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1278 in helper (tree_flatten.helper) (inline depth: 3)
V0914 01:48:01.915000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 leaves.append(node)
V0914 01:48:01.915000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1279 in helper (tree_flatten.helper) (inline depth: 3)
V0914 01:48:01.915000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return _LEAF_SPEC
V0914 01:48:01.916000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1291 in tree_flatten (tree_flatten) (inline depth: 2)
V0914 01:48:01.916000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return leaves, treespec
V0914 01:48:01.921000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1294 in tree_unflatten (tree_unflatten) (inline depth: 2)
V0914 01:48:01.921000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def tree_unflatten(leaves: Iterable[Any], treespec: TreeSpec) -> PyTree:
V0914 01:48:01.921000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1298 in tree_unflatten (tree_unflatten) (inline depth: 2)
V0914 01:48:01.921000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if not isinstance(treespec, TreeSpec):
V0914 01:48:01.922000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1303 in tree_unflatten (tree_unflatten) (inline depth: 2)
V0914 01:48:01.922000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return treespec.unflatten(leaves)
V0914 01:48:01.924000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1195 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:01.924000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def unflatten(self, leaves: Iterable[Any]) -> PyTree:
V0914 01:48:01.924000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1196 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:01.924000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if not isinstance(leaves, (list, tuple)):
V0914 01:48:01.924000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1198 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:01.924000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if len(leaves) != self.num_leaves:
V0914 01:48:01.925000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1204 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:01.925000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.is_leaf():
V0914 01:48:01.926000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1109 in is_leaf (TreeSpec.is_leaf) (inline depth: 4)
V0914 01:48:01.926000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def is_leaf(self) -> bool:
V0914 01:48:01.926000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1110 in is_leaf (TreeSpec.is_leaf) (inline depth: 4)
V0914 01:48:01.926000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return self.num_nodes == 1 and self.num_leaves == 1
V0914 01:48:01.927000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1205 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:01.927000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return leaves[0]
V0914 01:48:01.927000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:98 in forward (GPT.forward)
V0914 01:48:01.927000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             for block in self.transformer.h:
V0914 01:48:01.928000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:99 in forward (GPT.forward)
V0914 01:48:01.928000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 x = block(x, cos, sin, mask, input_pos)
V0914 01:48:01.929000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:145 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.929000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, *args, **kwargs):
V0914 01:48:01.929000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:149 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.929000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.checkpoint_impl == CheckpointImpl.REENTRANT and kwargs != {}:
V0914 01:48:01.930000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py:352 in cmp_eq (cmp_eq) (inline depth: 2)
V0914 01:48:01.930000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def cmp_eq(a, b):
V0914 01:48:01.930000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py:361 in cmp_eq (cmp_eq) (inline depth: 2)
V0914 01:48:01.930000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         result = a.__eq__(b)
V0914 01:48:01.930000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py:362 in cmp_eq (cmp_eq) (inline depth: 2)
V0914 01:48:01.930000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if result is NotImplemented:
V0914 01:48:01.931000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/_dynamo/polyfills/__init__.py:364 in cmp_eq (cmp_eq) (inline depth: 2)
V0914 01:48:01.931000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return result is not NotImplemented and result
V0914 01:48:01.931000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.931000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:01.931000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:172 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.931000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     self._checkpoint_wrapped_module, *args, **kwargs
V0914 01:48:01.932000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:46 in __getattr__ (ActivationWrapper.__getattr__) (inline depth: 2)
V0914 01:48:01.932000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def __getattr__(self, name: str) -> Any:
V0914 01:48:01.932000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:48 in __getattr__ (ActivationWrapper.__getattr__) (inline depth: 2)
V0914 01:48:01.932000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             try:
V0914 01:48:01.933000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:49 in __getattr__ (ActivationWrapper.__getattr__) (inline depth: 2)
V0914 01:48:01.933000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return super().__getattr__(name)  # defer to nn.Module's logic
V0914 01:48:01.933000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1951 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.933000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def __getattr__(self, name: str) -> Union[Tensor, "Module"]:
V0914 01:48:01.934000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1952 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.934000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if "_parameters" in self.__dict__:
V0914 01:48:01.935000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1953 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.935000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 _parameters = self.__dict__["_parameters"]
V0914 01:48:01.937000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1954 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.937000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if name in _parameters:
V0914 01:48:01.938000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1956 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.938000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if "_buffers" in self.__dict__:
V0914 01:48:01.939000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1957 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.939000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 _buffers = self.__dict__["_buffers"]
V0914 01:48:01.940000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1958 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.940000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if name in _buffers:
V0914 01:48:01.942000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1960 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.942000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if "_modules" in self.__dict__:
V0914 01:48:01.943000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1961 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.943000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 modules = self.__dict__["_modules"]
V0914 01:48:01.944000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1962 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.944000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if name in modules:
V0914 01:48:01.946000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1963 in __getattr__ (Module.to.to.to.__getattr__) (inline depth: 3)
V0914 01:48:01.946000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     return modules[name]
V0914 01:48:01.947000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.947000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:01.947000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:172 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.947000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     self._checkpoint_wrapped_module, *args, **kwargs
V0914 01:48:01.948000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.948000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:01.948000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:172 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.948000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     self._checkpoint_wrapped_module, *args, **kwargs
V0914 01:48:01.948000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward (CheckpointWrapper.forward) (inline depth: 1)
V0914 01:48:01.948000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:01.949000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:199 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.949000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(
V0914 01:48:01.950000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:228 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.950000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = self.norm_1(x)
V0914 01:48:01.951000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.951000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:01.952000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.952000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:01.953000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.953000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:01.955000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.955000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:01.958000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.958000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:01.961000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.961000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:01.965000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:01.965000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:01.968000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:229 in forward (Block.forward) (inline depth: 2)
V0914 01:48:01.968000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             attention_output = self.attn(x_normed, cos, sin, mask, input_pos)
V0914 01:48:01.969000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:259 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.969000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(
V0914 01:48:01.970000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:267 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.970000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             B, T, C = x.size()  # batch size, sequence length, embedding dimensionality (n_embd)
V0914 01:48:01.971000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:269 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.971000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             qkv = self.attn(x)
V0914 01:48:01.973000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.973000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:01.973000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:01.973000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:01.976000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:272 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.976000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q_per_kv = self.config.n_head // self.config.n_query_groups
V0914 01:48:01.978000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:273 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.978000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             total_qkv = q_per_kv + 2  # each group has 1+ queries, 1 key, and 1 value
V0914 01:48:01.979000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:274 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.979000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             qkv = qkv.view(B, T, self.config.n_query_groups, total_qkv, self.config.head_size)
V0914 01:48:01.982000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:275 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.982000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             qkv = qkv.permute(0, 2, 3, 1, 4)  # (B, n_query_groups, total_qkv, T, hs)
V0914 01:48:01.984000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:278 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.984000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q, k, v = qkv.split((q_per_kv, 1, 1), dim=2)
V0914 01:48:01.986000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:283 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.986000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.config.n_query_groups != self.config.n_head and (input_pos is None or self.config.n_query_groups != 1):
V0914 01:48:01.988000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:284 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.988000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 k = k.expand(B, self.config.n_query_groups, q_per_kv, T, self.config.head_size)
V0914 01:48:01.991000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:285 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.991000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 v = v.expand(B, self.config.n_query_groups, q_per_kv, T, self.config.head_size)
V0914 01:48:01.993000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:287 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.993000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q = q.reshape(B, -1, T, self.config.head_size)  # (B, nh_q, T, hs)
V0914 01:48:01.996000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:288 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.996000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             k = k.reshape(B, -1, T, self.config.head_size)  # (B, nh_k, T, hs)
V0914 01:48:01.998000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:289 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:01.998000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             v = v.reshape(B, -1, T, self.config.head_size)  # (B, nh_v, T, hs)
V0914 01:48:02.001000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:291 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.001000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q_roped = apply_rope(q[..., : self.config.rope_n_elem], cos, sin)
V0914 01:48:02.004000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:579 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.004000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def apply_rope(x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:
V0914 01:48:02.004000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:580 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.004000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         head_size = x.size(-1)
V0914 01:48:02.004000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:581 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.004000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         x1 = x[..., : head_size // 2]  # (B, nh, T, hs/2)
V0914 01:48:02.006000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:582 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.006000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         x2 = x[..., head_size // 2 :]  # (B, nh, T, hs/2)
V0914 01:48:02.007000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:583 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.007000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         rotated = torch.cat((-x2, x1), dim=-1)  # (B, nh, T, hs)
V0914 01:48:02.008000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:584 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.008000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if cos.dim() > 1:
V0914 01:48:02.009000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:588 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.009000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             cos = cos.unsqueeze(-3)
V0914 01:48:02.010000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:589 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.010000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             sin = sin.unsqueeze(-3)
V0914 01:48:02.011000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:591 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.011000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         roped = (x * cos) + (rotated * sin)
V0914 01:48:02.014000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:592 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.014000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return roped.to(dtype=x.dtype)
V0914 01:48:02.015000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:292 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.015000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             k_roped = apply_rope(k[..., : self.config.rope_n_elem], cos, sin)
V0914 01:48:02.017000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:579 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.017000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def apply_rope(x: torch.Tensor, cos: torch.Tensor, sin: torch.Tensor) -> torch.Tensor:
V0914 01:48:02.018000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:580 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.018000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         head_size = x.size(-1)
V0914 01:48:02.018000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:581 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.018000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         x1 = x[..., : head_size // 2]  # (B, nh, T, hs/2)
V0914 01:48:02.019000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:582 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.019000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         x2 = x[..., head_size // 2 :]  # (B, nh, T, hs/2)
V0914 01:48:02.020000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:583 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.020000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         rotated = torch.cat((-x2, x1), dim=-1)  # (B, nh, T, hs)
V0914 01:48:02.022000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:584 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.022000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if cos.dim() > 1:
V0914 01:48:02.023000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:588 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.023000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             cos = cos.unsqueeze(-3)
V0914 01:48:02.024000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:589 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.024000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             sin = sin.unsqueeze(-3)
V0914 01:48:02.025000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:591 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.025000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         roped = (x * cos) + (rotated * sin)
V0914 01:48:02.027000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:592 in apply_rope (apply_rope) (inline depth: 4)
V0914 01:48:02.027000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return roped.to(dtype=x.dtype)
V0914 01:48:02.027000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:293 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.027000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             q = torch.cat((q_roped, q[..., self.config.rope_n_elem :]), dim=-1)
V0914 01:48:02.030000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:294 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.030000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             k = torch.cat((k_roped, k[..., self.config.rope_n_elem :]), dim=-1)
V0914 01:48:02.033000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:296 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.033000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if input_pos is not None:
V0914 01:48:02.034000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:301 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.034000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.apply_sliding_window_attention:
V0914 01:48:02.036000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:319 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.036000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             y = self.scaled_dot_product_attention(q, k, v, mask)
V0914 01:48:02.037000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:326 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.037000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def scaled_dot_product_attention(
V0914 01:48:02.037000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:329 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.037000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             scale = 1.0 / math.sqrt(self.config.attention_scores_scalar or self.config.head_size)
V0914 01:48:02.038000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:332 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.038000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.config.attention_logit_softcapping is not None:
V0914 01:48:02.039000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:333 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.039000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scale = 1.0 / math.sqrt(self.config.attention_scores_scalar or self.config.head_size)
V0914 01:48:02.040000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:334 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.040000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scores = q @ k.mT * scale
V0914 01:48:02.043000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:336 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.043000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     torch.tanh(scores / self.config.attention_logit_softcapping) * self.config.attention_logit_softcapping
V0914 01:48:02.045000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:335 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.045000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scores = (
V0914 01:48:02.046000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:338 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.046000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 if mask is None:
V0914 01:48:02.046000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:339 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.046000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     mask = torch.ones(q.size(2), q.size(2), dtype=q.dtype, device=q.device).triu(diagonal=1)
V0914 01:48:02.048000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:340 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.048000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                     mask.masked_fill_(mask.bool(), torch.finfo(q.dtype).min)
V0914 01:48:02.050000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:341 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.050000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scores = scores + mask
V0914 01:48:02.051000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:342 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.051000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 scores = torch.nn.functional.softmax(scores, dim=-1, dtype=torch.float).to(dtype=q.dtype)
V0914 01:48:02.053000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:343 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.053000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 y = scores @ v
V0914 01:48:02.055000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:348 in scaled_dot_product_attention (CausalSelfAttention.scaled_dot_product_attention) (inline depth: 4)
V0914 01:48:02.055000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return y.transpose(1, 2)
V0914 01:48:02.056000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:321 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.056000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             y = y.reshape(B, T, self.config.head_size * self.config.n_head)  # re-assemble all head outputs side by side
V0914 01:48:02.059000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:324 in forward (CausalSelfAttention.forward) (inline depth: 3)
V0914 01:48:02.059000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return self.proj(y)
V0914 01:48:02.061000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:02.061000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:02.061000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:02.061000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:02.064000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:230 in forward (Block.forward) (inline depth: 2)
V0914 01:48:02.064000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             attention_output = self.post_attention_norm(attention_output)
V0914 01:48:02.065000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.065000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:02.066000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.066000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:02.067000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.067000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:02.069000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.069000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.071000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.071000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.075000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.075000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.078000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.078000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.081000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:232 in forward (Block.forward) (inline depth: 2)
V0914 01:48:02.081000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.config.parallel_residual:
V0914 01:48:02.082000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:236 in forward (Block.forward) (inline depth: 2)
V0914 01:48:02.082000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 x = attention_output + x
V0914 01:48:02.083000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:237 in forward (Block.forward) (inline depth: 2)
V0914 01:48:02.083000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 x = self.post_mlp_norm(self.mlp(self.norm_2(x))) + x
V0914 01:48:02.084000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.084000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:02.085000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.085000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:02.086000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.086000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:02.088000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.088000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.091000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.091000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.094000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.094000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.097000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.097000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.101000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:405 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:02.101000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:02.102000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:406 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:02.102000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_fc_1 = self.fc_1(x)
V0914 01:48:02.104000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:02.104000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:02.104000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:02.104000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:02.107000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:407 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:02.107000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_fc_2 = self.fc_2(x)
V0914 01:48:02.109000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:02.109000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:02.109000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:02.109000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:02.112000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:408 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:02.112000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = torch.nn.functional.gelu(x_fc_1, approximate=self.config.gelu_approximate) * x_fc_2
V0914 01:48:02.115000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:409 in forward (GemmaMLP.forward) (inline depth: 3)
V0914 01:48:02.115000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return self.proj(x)
V0914 01:48:02.117000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:02.117000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:02.117000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 4)
V0914 01:48:02.117000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:02.120000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.120000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:02.121000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.121000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:02.123000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.123000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:02.124000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.124000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.127000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.127000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.131000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.131000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.134000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 3)
V0914 01:48:02.134000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.137000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:238 in forward (Block.forward) (inline depth: 2)
V0914 01:48:02.137000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return x
V0914 01:48:02.138000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1268 in tree_flatten (tree_flatten) (inline depth: 2)
V0914 01:48:02.138000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def tree_flatten(
V0914 01:48:02.138000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1276 in tree_flatten (tree_flatten.helper) (inline depth: 2)
V0914 01:48:02.138000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def helper(node: PyTree, leaves: list[Any]) -> TreeSpec:
V0914 01:48:02.139000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1289 in tree_flatten (tree_flatten) (inline depth: 2)
V0914 01:48:02.139000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         leaves: list[Any] = []
V0914 01:48:02.139000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1290 in tree_flatten (tree_flatten) (inline depth: 2)
V0914 01:48:02.139000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         treespec = helper(tree, leaves)
V0914 01:48:02.140000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1276 in helper (tree_flatten.helper) (inline depth: 3)
V0914 01:48:02.140000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def helper(node: PyTree, leaves: list[Any]) -> TreeSpec:
V0914 01:48:02.140000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1277 in helper (tree_flatten.helper) (inline depth: 3)
V0914 01:48:02.140000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if tree_is_leaf(node, is_leaf=is_leaf):
V0914 01:48:02.141000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1024 in tree_is_leaf (tree_is_leaf) (inline depth: 4)
V0914 01:48:02.141000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def tree_is_leaf(
V0914 01:48:02.141000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1043 in tree_is_leaf (tree_is_leaf) (inline depth: 4)
V0914 01:48:02.141000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if is_leaf is not None and is_leaf(tree):
V0914 01:48:02.141000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1045 in tree_is_leaf (tree_is_leaf) (inline depth: 4)
V0914 01:48:02.141000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return _get_node_type(tree) not in SUPPORTED_NODES
V0914 01:48:02.142000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1012 in _get_node_type (_get_node_type) (inline depth: 5)
V0914 01:48:02.142000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def _get_node_type(tree: Any) -> Any:
V0914 01:48:02.142000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1013 in _get_node_type (_get_node_type) (inline depth: 5)
V0914 01:48:02.142000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         node_type = type(tree)
V0914 01:48:02.143000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1018 in _get_node_type (_get_node_type) (inline depth: 5)
V0914 01:48:02.143000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if is_namedtuple_class(node_type):
V0914 01:48:02.143000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:679 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:02.143000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def is_namedtuple_class(cls: type) -> bool:
V0914 01:48:02.143000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:682 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:02.143000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             isinstance(cls, type)
V0914 01:48:02.144000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:683 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:02.144000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             and issubclass(cls, tuple)
V0914 01:48:02.144000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:682 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:02.144000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             isinstance(cls, type)
V0914 01:48:02.145000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:681 in is_namedtuple_class (is_namedtuple_class) (inline depth: 6)
V0914 01:48:02.145000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return (
V0914 01:48:02.145000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1020 in _get_node_type (_get_node_type) (inline depth: 5)
V0914 01:48:02.145000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return node_type
V0914 01:48:02.146000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1278 in helper (tree_flatten.helper) (inline depth: 3)
V0914 01:48:02.146000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 leaves.append(node)
V0914 01:48:02.146000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1279 in helper (tree_flatten.helper) (inline depth: 3)
V0914 01:48:02.146000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return _LEAF_SPEC
V0914 01:48:02.147000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1291 in tree_flatten (tree_flatten) (inline depth: 2)
V0914 01:48:02.147000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return leaves, treespec
V0914 01:48:02.150000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1294 in tree_unflatten (tree_unflatten) (inline depth: 2)
V0914 01:48:02.150000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]     def tree_unflatten(leaves: Iterable[Any], treespec: TreeSpec) -> PyTree:
V0914 01:48:02.151000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1298 in tree_unflatten (tree_unflatten) (inline depth: 2)
V0914 01:48:02.151000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         if not isinstance(treespec, TreeSpec):
V0914 01:48:02.151000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1303 in tree_unflatten (tree_unflatten) (inline depth: 2)
V0914 01:48:02.151000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         return treespec.unflatten(leaves)
V0914 01:48:02.152000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1195 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:02.152000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def unflatten(self, leaves: Iterable[Any]) -> PyTree:
V0914 01:48:02.152000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1196 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:02.152000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if not isinstance(leaves, (list, tuple)):
V0914 01:48:02.153000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1198 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:02.153000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if len(leaves) != self.num_leaves:
V0914 01:48:02.153000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1204 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:02.153000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.is_leaf():
V0914 01:48:02.154000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1109 in is_leaf (TreeSpec.is_leaf) (inline depth: 4)
V0914 01:48:02.154000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def is_leaf(self) -> bool:
V0914 01:48:02.154000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1110 in is_leaf (TreeSpec.is_leaf) (inline depth: 4)
V0914 01:48:02.154000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return self.num_nodes == 1 and self.num_leaves == 1
V0914 01:48:02.155000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/utils/_pytree.py:1205 in unflatten (TreeSpec.unflatten) (inline depth: 3)
V0914 01:48:02.155000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 return leaves[0]
V0914 01:48:02.155000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:98 in forward (GPT.forward)
V0914 01:48:02.155000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             for block in self.transformer.h:
V0914 01:48:02.155000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:100 in forward (GPT.forward)
V0914 01:48:02.155000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = self.transformer.ln_f(x)
V0914 01:48:02.156000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:641 in forward (RMSNorm.forward) (inline depth: 1)
V0914 01:48:02.156000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, x: torch.Tensor) -> torch.Tensor:
V0914 01:48:02.157000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:642 in forward (RMSNorm.forward) (inline depth: 1)
V0914 01:48:02.157000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             dtype = x.dtype
V0914 01:48:02.157000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward (RMSNorm.forward) (inline depth: 1)
V0914 01:48:02.157000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = x.float()
V0914 01:48:02.158000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward (RMSNorm.forward) (inline depth: 1)
V0914 01:48:02.158000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.159000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward (RMSNorm.forward) (inline depth: 1)
V0914 01:48:02.159000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.161000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward (RMSNorm.forward) (inline depth: 1)
V0914 01:48:02.161000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.163000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward (RMSNorm.forward) (inline depth: 1)
V0914 01:48:02.163000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.164000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:101 in forward (GPT.forward)
V0914 01:48:02.164000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             x = self.lm_head(x)  # (b, t, vocab_size)
V0914 01:48:02.165000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:130 in forward (Linear.forward) (inline depth: 1)
V0914 01:48:02.165000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]         def forward(self, input: Tensor) -> Tensor:
V0914 01:48:02.166000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py:134 in forward (Linear.forward) (inline depth: 1)
V0914 01:48:02.166000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return F.linear(input, self.weight, self.bias)
V0914 01:48:02.170000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:102 in forward (GPT.forward)
V0914 01:48:02.170000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             if self.config.final_logit_softcapping is not None:
V0914 01:48:02.170000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:103 in forward (GPT.forward)
V0914 01:48:02.170000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]                 x = torch.tanh(x / self.config.final_logit_softcapping) * self.config.final_logit_softcapping
V0914 01:48:02.174000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source] TRACE starts_line /usr/local/lib/python3.12/dist-packages/litgpt/model.py:104 in forward (GPT.forward)
V0914 01:48:02.174000 112965 torch/_dynamo/symbolic_convert.py:1245] [0/0] [__trace_source]             return x
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code] TRACED GRAPH
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]  ===== __compiled_fn_1_bb7c47e3_5315_4e29_aadb_2efcd4d7e970 =====
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]  /usr/local/lib/python3.12/dist-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]     def forward(self, L_idx_: "i64[1, 8192][8192, 1]cuda:0", L_self_buffers_cos_: "bf16[8192, 128][128, 1]cuda:0", L_self_buffers_sin_: "bf16[8192, 128][128, 1]cuda:0", L_self_modules_transformer_modules_wte_parameters_weight_: "bf16[256000, 2][2, 1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_: "bf16[8192, 2][2, 1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_: "bf16[2, 4096][4096, 1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_: "bf16[16, 2][2, 1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_: "bf16[16, 2][2, 1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_: "bf16[2, 16][16, 1]cuda:0", L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_: "bf16[8192, 2][2, 1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_: "bf16[2, 4096][4096, 1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_: "bf16[16, 2][2, 1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_: "bf16[16, 2][2, 1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_: "bf16[2, 16][16, 1]cuda:0", L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_transformer_modules_ln_f_parameters_weight_: "bf16[2][1]cuda:0", L_self_modules_lm_head_parameters_weight_: "bf16[256000, 2][2, 1]cuda:0"):
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_idx_ = L_idx_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_buffers_cos_ = L_self_buffers_cos_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_buffers_sin_ = L_self_buffers_sin_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_wte_parameters_weight_ = L_self_modules_transformer_modules_wte_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_ = L_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_ = L_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_transformer_modules_ln_f_parameters_weight_ = L_self_modules_transformer_modules_ln_f_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         l_self_modules_lm_head_parameters_weight_ = L_self_modules_lm_head_parameters_weight_
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:90 in forward, code: cos = self.cos[:T]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         cos: "bf16[8192, 128][128, 1]cuda:0" = l_self_buffers_cos_[slice(None, 8192, None)];  l_self_buffers_cos_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:91 in forward, code: sin = self.sin[:T]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         sin: "bf16[8192, 128][128, 1]cuda:0" = l_self_buffers_sin_[slice(None, 8192, None)];  l_self_buffers_sin_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:94 in forward, code: x = self.transformer.wte(idx)  # token embeddings of shape (b, t, n_embd)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = torch.nn.functional.embedding(l_idx_, l_self_modules_transformer_modules_wte_parameters_weight_, None, None, 2.0, False, False);  l_idx_ = l_self_modules_transformer_modules_wte_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:96 in forward, code: x = x * torch.tensor(self.config.n_embd**0.5, dtype=x.dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         tensor: "bf16[][]cpu" = torch.tensor(1.4142135623730951, dtype = torch.bfloat16)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x_1: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = x * tensor;  x = tensor = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py:171 in forward, code: return self.checkpoint_fn(  # type: ignore[misc]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         wrap_body_0 = self.wrap_body_0
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         tag_activation_checkpoint = torch.ops.higher_order.tag_activation_checkpoint(wrap_body_0, x_1, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_, cos, sin, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_, use_reentrant = False);  wrap_body_0 = x_1 = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_ = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_ = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_ = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_ = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_ = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_ = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_ = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_ = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x_2: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = tag_activation_checkpoint[0];  tag_activation_checkpoint = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         wrap_body_1 = self.wrap_body_1
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         tag_activation_checkpoint_1 = torch.ops.higher_order.tag_activation_checkpoint(wrap_body_1, x_2, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_, cos, sin, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_, use_reentrant = False);  wrap_body_1 = x_2 = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_ = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_ = cos = sin = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_ = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_ = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_ = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_ = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_ = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_ = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x_3: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = tag_activation_checkpoint_1[0];  tag_activation_checkpoint_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x_4: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_3.float();  x_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         mul_1: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_4 * x_4
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         norm_x: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul_1, dim = -1, keepdim = True);  mul_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         add: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x + 1e-05;  norm_x = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         rsqrt: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add);  add = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x_normed: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_4 * rsqrt;  x_4 = rsqrt = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         weight: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_ln_f_parameters_weight_;  l_self_modules_transformer_modules_ln_f_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         float_2: "f32[2][1]cuda:0" = weight.float();  weight = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         mul_3: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed * float_2;  x_normed = float_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x_5: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_3.to(dtype = torch.bfloat16);  mul_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:101 in forward, code: x = self.lm_head(x)  # (b, t, vocab_size)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x_6: "bf16[1, 8192, 256000][2097152000, 256000, 1]cuda:0" = torch._C._nn.linear(x_5, l_self_modules_lm_head_parameters_weight_, None);  x_5 = l_self_modules_lm_head_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]          # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:103 in forward, code: x = torch.tanh(x / self.config.final_logit_softcapping) * self.config.final_logit_softcapping
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         truediv: "bf16[1, 8192, 256000][2097152000, 256000, 1]cuda:0" = x_6 / 30.0;  x_6 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         tanh: "bf16[1, 8192, 256000][2097152000, 256000, 1]cuda:0" = torch.tanh(truediv);  truediv = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         x_7: "bf16[1, 8192, 256000][2097152000, 256000, 1]cuda:0" = tanh * 30.0;  tanh = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         return (x_7,)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]     class wrap_body_0(torch.nn.Module):
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         def forward(self, x_1: "bf16[1, 8192, 2][16384, 2, 1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_: "bf16[2][1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_: "bf16[8192, 2][2, 1]cuda:0", cos: "bf16[8192, 128][128, 1]cuda:0", sin: "bf16[8192, 128][128, 1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_: "bf16[2, 4096][4096, 1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_: "bf16[2][1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_: "bf16[2][1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_: "bf16[16, 2][2, 1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_: "bf16[16, 2][2, 1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_: "bf16[2, 16][16, 1]cuda:0", l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_: "bf16[2][1]cuda:0"):
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_1.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x * x
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             norm_x: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul, dim = -1, keepdim = True);  mul = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             add: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x + 1e-05;  norm_x = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rsqrt: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add);  add = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x * rsqrt;  x = rsqrt = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             weight: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_;  l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             float_2: "f32[2][1]cuda:0" = weight.float();  weight = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_2: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed * float_2;  x_normed = float_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed_1: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_2.to(dtype = torch.bfloat16);  mul_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:269 in forward, code: qkv = self.attn(x)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             qkv: "bf16[1, 8192, 8192][67108864, 8192, 1]cuda:0" = torch._C._nn.linear(x_normed_1, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_, None);  x_normed_1 = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:274 in forward, code: qkv = qkv.view(B, T, self.config.n_query_groups, total_qkv, self.config.head_size)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             qkv_1: "bf16[1, 8192, 16, 4, 128][67108864, 8192, 512, 128, 1]cuda:0" = qkv.view(1, 8192, 16, 4, 128);  qkv = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:275 in forward, code: qkv = qkv.permute(0, 2, 3, 1, 4)  # (B, n_query_groups, total_qkv, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             qkv_2: "bf16[1, 16, 4, 8192, 128][67108864, 512, 128, 8192, 1]cuda:0" = qkv_1.permute(0, 2, 3, 1, 4);  qkv_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:278 in forward, code: q, k, v = qkv.split((q_per_kv, 1, 1), dim=2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             split = qkv_2.split((2, 1, 1), dim = 2);  qkv_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             q: "bf16[1, 16, 2, 8192, 128][67108864, 512, 128, 8192, 1]cuda:0" = split[0]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k: "bf16[1, 16, 1, 8192, 128][67108864, 512, 128, 8192, 1]cuda:0" = split[1]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             v: "bf16[1, 16, 1, 8192, 128][67108864, 512, 128, 8192, 1]cuda:0" = split[2];  split = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:284 in forward, code: k = k.expand(B, self.config.n_query_groups, q_per_kv, T, self.config.head_size)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k_1: "bf16[1, 16, 2, 8192, 128][67108864, 512, 0, 8192, 1]cuda:0" = k.expand(1, 16, 2, 8192, 128);  k = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:285 in forward, code: v = v.expand(B, self.config.n_query_groups, q_per_kv, T, self.config.head_size)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             v_1: "bf16[1, 16, 2, 8192, 128][67108864, 512, 0, 8192, 1]cuda:0" = v.expand(1, 16, 2, 8192, 128);  v = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:287 in forward, code: q = q.reshape(B, -1, T, self.config.head_size)  # (B, nh_q, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             q_1: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = q.reshape(1, -1, 8192, 128);  q = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:288 in forward, code: k = k.reshape(B, -1, T, self.config.head_size)  # (B, nh_k, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k_2: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = k_1.reshape(1, -1, 8192, 128);  k_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:289 in forward, code: v = v.reshape(B, -1, T, self.config.head_size)  # (B, nh_v, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             v_2: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = v_1.reshape(1, -1, 8192, 128);  v_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:291 in forward, code: q_roped = apply_rope(q[..., : self.config.rope_n_elem], cos, sin)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getitem_3: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = q_1[(Ellipsis, slice(None, 128, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:581 in apply_rope, code: x1 = x[..., : head_size // 2]  # (B, nh, T, hs/2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x1: "bf16[1, 32, 8192, 64][33554432, 1048576, 128, 1]cuda:0" = getitem_3[(Ellipsis, slice(None, 64, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:582 in apply_rope, code: x2 = x[..., head_size // 2 :]  # (B, nh, T, hs/2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x2: "bf16[1, 32, 8192, 64][33554432, 1048576, 128, 1]cuda:0" = getitem_3[(Ellipsis, slice(64, None, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:583 in apply_rope, code: rotated = torch.cat((-x2, x1), dim=-1)  # (B, nh, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             neg: "bf16[1, 32, 8192, 64][16777216, 524288, 64, 1]cuda:0" = -x2;  x2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rotated: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = torch.cat((neg, x1), dim = -1);  neg = x1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:588 in apply_rope, code: cos = cos.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             cos_1: "bf16[1, 8192, 128][1048576, 128, 1]cuda:0" = cos.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:589 in apply_rope, code: sin = sin.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             sin_1: "bf16[1, 8192, 128][1048576, 128, 1]cuda:0" = sin.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:591 in apply_rope, code: roped = (x * cos) + (rotated * sin)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_3: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = getitem_3 * cos_1;  getitem_3 = cos_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_4: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = rotated * sin_1;  rotated = sin_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             roped: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = mul_3 + mul_4;  mul_3 = mul_4 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:592 in apply_rope, code: return roped.to(dtype=x.dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             q_roped: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = roped.to(dtype = torch.bfloat16);  roped = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:292 in forward, code: k_roped = apply_rope(k[..., : self.config.rope_n_elem], cos, sin)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getitem_6: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = k_2[(Ellipsis, slice(None, 128, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:581 in apply_rope, code: x1 = x[..., : head_size // 2]  # (B, nh, T, hs/2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x1_1: "bf16[1, 32, 8192, 64][33554432, 1048576, 128, 1]cuda:0" = getitem_6[(Ellipsis, slice(None, 64, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:582 in apply_rope, code: x2 = x[..., head_size // 2 :]  # (B, nh, T, hs/2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x2_1: "bf16[1, 32, 8192, 64][33554432, 1048576, 128, 1]cuda:0" = getitem_6[(Ellipsis, slice(64, None, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:583 in apply_rope, code: rotated = torch.cat((-x2, x1), dim=-1)  # (B, nh, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             neg_1: "bf16[1, 32, 8192, 64][16777216, 524288, 64, 1]cuda:0" = -x2_1;  x2_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rotated_1: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = torch.cat((neg_1, x1_1), dim = -1);  neg_1 = x1_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:588 in apply_rope, code: cos = cos.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             cos_2: "bf16[1, 8192, 128][1048576, 128, 1]cuda:0" = cos.unsqueeze(-3);  cos = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:589 in apply_rope, code: sin = sin.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             sin_2: "bf16[1, 8192, 128][1048576, 128, 1]cuda:0" = sin.unsqueeze(-3);  sin = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:591 in apply_rope, code: roped = (x * cos) + (rotated * sin)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_5: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = getitem_6 * cos_2;  getitem_6 = cos_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_6: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = rotated_1 * sin_2;  rotated_1 = sin_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             roped_1: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = mul_5 + mul_6;  mul_5 = mul_6 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:592 in apply_rope, code: return roped.to(dtype=x.dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k_roped: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = roped_1.to(dtype = torch.bfloat16);  roped_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:293 in forward, code: q = torch.cat((q_roped, q[..., self.config.rope_n_elem :]), dim=-1)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getitem_9: "bf16[1, 32, 8192, 0][33554432, 1048576, 128, 1]cuda:0" = q_1[(Ellipsis, slice(128, None, None))];  q_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             q_2: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = torch.cat((q_roped, getitem_9), dim = -1);  q_roped = getitem_9 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:294 in forward, code: k = torch.cat((k_roped, k[..., self.config.rope_n_elem :]), dim=-1)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getitem_10: "bf16[1, 32, 8192, 0][33554432, 1048576, 128, 1]cuda:0" = k_2[(Ellipsis, slice(128, None, None))];  k_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k_3: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = torch.cat((k_roped, getitem_10), dim = -1);  k_roped = getitem_10 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:313 in forward, code: mask = torch.ones(T, T, dtype=q.dtype, device=q.device).triu(diagonal=1)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             ones: "bf16[8192, 8192][8192, 1]cuda:0" = torch.ones(8192, 8192, dtype = torch.bfloat16, device = device(type='cuda', index=0))
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mask: "bf16[8192, 8192][8192, 1]cuda:0" = ones.triu(diagonal = 1);  ones = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:314 in forward, code: mask.masked_fill_(mask.bool(), float("-inf"))
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             bool_1: "b8[8192, 8192][8192, 1]cuda:0" = mask.bool()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             masked_fill_: "bf16[8192, 8192][8192, 1]cuda:0" = mask.masked_fill_(bool_1, -inf);  bool_1 = masked_fill_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:315 in forward, code: sliding_window_bias = torch.ones_like(mask).tril(diagonal=-self.config.sliding_window_size)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             ones_like: "bf16[8192, 8192][8192, 1]cuda:0" = torch.ones_like(mask)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             sliding_window_bias: "bf16[8192, 8192][8192, 1]cuda:0" = ones_like.tril(diagonal = -4096);  ones_like = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:316 in forward, code: sliding_window_bias.masked_fill_(sliding_window_bias.bool(), float("-inf"))
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             bool_2: "b8[8192, 8192][8192, 1]cuda:0" = sliding_window_bias.bool()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             masked_fill__1: "bf16[8192, 8192][8192, 1]cuda:0" = sliding_window_bias.masked_fill_(bool_2, -inf);  bool_2 = masked_fill__1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:317 in forward, code: mask += sliding_window_bias
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mask += sliding_window_bias;  mask_1: "bf16[8192, 8192][8192, 1]cuda:0" = mask;  mask = sliding_window_bias = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:334 in scaled_dot_product_attention, code: scores = q @ k.mT * scale
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getattr_1: "bf16[1, 32, 128, 8192][33554432, 1048576, 1, 128]cuda:0" = k_3.mT;  k_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             matmul: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = q_2 @ getattr_1;  q_2 = getattr_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             scores: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = matmul * 0.08333333333333333;  matmul = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:336 in scaled_dot_product_attention, code: torch.tanh(scores / self.config.attention_logit_softcapping) * self.config.attention_logit_softcapping
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             truediv: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = scores / 50.0;  scores = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             tanh: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = torch.tanh(truediv);  truediv = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             scores_1: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = tanh * 50.0;  tanh = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:341 in scaled_dot_product_attention, code: scores = scores + mask
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             scores_2: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = scores_1 + mask_1;  scores_1 = mask_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:342 in scaled_dot_product_attention, code: scores = torch.nn.functional.softmax(scores, dim=-1, dtype=torch.float).to(dtype=q.dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             softmax: "f32[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = torch.nn.functional.softmax(scores_2, dim = -1, dtype = torch.float32);  scores_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             scores_3: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = softmax.to(dtype = torch.bfloat16);  softmax = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:343 in scaled_dot_product_attention, code: y = scores @ v
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             y: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = scores_3 @ v_2;  scores_3 = v_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:348 in scaled_dot_product_attention, code: return y.transpose(1, 2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             y_1: "bf16[1, 8192, 32, 128][33554432, 128, 1048576, 1]cuda:0" = y.transpose(1, 2);  y = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:321 in forward, code: y = y.reshape(B, T, self.config.head_size * self.config.n_head)  # re-assemble all head outputs side by side
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             y_2: "bf16[1, 8192, 4096][33554432, 4096, 1]cuda:0" = y_1.reshape(1, 8192, 4096);  y_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:324 in forward, code: return self.proj(y)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             attention_output: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = torch._C._nn.linear(y_2, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_, None);  y_2 = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_2: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = attention_output.float();  attention_output = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_9: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_2 * x_2
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             norm_x_1: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul_9, dim = -1, keepdim = True);  mul_9 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             add_5: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x_1 + 1e-05;  norm_x_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rsqrt_1: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add_5);  add_5 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed_2: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_2 * rsqrt_1;  x_2 = rsqrt_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             weight_1: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_;  l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             float_4: "f32[2][1]cuda:0" = weight_1.float();  weight_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_11: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed_2 * float_4;  x_normed_2 = float_4 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             attention_output_1: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_11.to(dtype = torch.bfloat16);  mul_11 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:236 in forward, code: x = attention_output + x
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_3: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = attention_output_1 + x_1;  attention_output_1 = x_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_4: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_3.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_12: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_4 * x_4
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             norm_x_2: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul_12, dim = -1, keepdim = True);  mul_12 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             add_8: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x_2 + 1e-05;  norm_x_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rsqrt_2: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add_8);  add_8 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed_3: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_4 * rsqrt_2;  x_4 = rsqrt_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             weight_2: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_;  l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             float_6: "f32[2][1]cuda:0" = weight_2.float();  weight_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_14: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed_3 * float_6;  x_normed_3 = float_6 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             to_5: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_14.to(dtype = torch.bfloat16);  mul_14 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:406 in forward, code: x_fc_1 = self.fc_1(x)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_fc_1: "bf16[1, 8192, 16][131072, 16, 1]cuda:0" = torch._C._nn.linear(to_5, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_, None);  l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:407 in forward, code: x_fc_2 = self.fc_2(x)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_fc_2: "bf16[1, 8192, 16][131072, 16, 1]cuda:0" = torch._C._nn.linear(to_5, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_, None);  to_5 = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:408 in forward, code: x = torch.nn.functional.gelu(x_fc_1, approximate=self.config.gelu_approximate) * x_fc_2
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             gelu: "bf16[1, 8192, 16][131072, 16, 1]cuda:0" = torch._C._nn.gelu(x_fc_1, approximate = 'tanh');  x_fc_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_5: "bf16[1, 8192, 16][131072, 16, 1]cuda:0" = gelu * x_fc_2;  gelu = x_fc_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:409 in forward, code: return self.proj(x)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             linear_4: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = torch._C._nn.linear(x_5, l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_, None);  x_5 = l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_6: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = linear_4.float();  linear_4 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_16: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_6 * x_6
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             norm_x_3: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul_16, dim = -1, keepdim = True);  mul_16 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             add_10: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x_3 + 1e-05;  norm_x_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rsqrt_3: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add_10);  add_10 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed_4: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_6 * rsqrt_3;  x_6 = rsqrt_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             weight_3: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_;  l_self_modules_transformer_modules_h_modules_0_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             float_8: "f32[2][1]cuda:0" = weight_3.float();  weight_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_18: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed_4 * float_8;  x_normed_4 = float_8 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             to_6: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_18.to(dtype = torch.bfloat16);  mul_18 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:237 in forward, code: x = self.post_mlp_norm(self.mlp(self.norm_2(x))) + x
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_7: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = to_6 + x_3;  to_6 = x_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             return (x_7,)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]     class wrap_body_1(torch.nn.Module):
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]         def forward(self, x_2: "bf16[1, 8192, 2][16384, 2, 1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_: "bf16[2][1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_: "bf16[8192, 2][2, 1]cuda:0", cos: "bf16[8192, 128][128, 1]cuda:0", sin: "bf16[8192, 128][128, 1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_: "bf16[2, 4096][4096, 1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_: "bf16[2][1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_: "bf16[2][1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_: "bf16[16, 2][2, 1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_: "bf16[16, 2][2, 1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_: "bf16[2, 16][16, 1]cuda:0", l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_: "bf16[2][1]cuda:0"):
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_2.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x * x
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             norm_x: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul, dim = -1, keepdim = True);  mul = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             add: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x + 1e-05;  norm_x = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rsqrt: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add);  add = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x * rsqrt;  x = rsqrt = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             weight: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_;  l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_1_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             float_2: "f32[2][1]cuda:0" = weight.float();  weight = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_2: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed * float_2;  x_normed = float_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed_1: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_2.to(dtype = torch.bfloat16);  mul_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:269 in forward, code: qkv = self.attn(x)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             qkv: "bf16[1, 8192, 8192][67108864, 8192, 1]cuda:0" = torch._C._nn.linear(x_normed_1, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_, None);  x_normed_1 = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_attn_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:274 in forward, code: qkv = qkv.view(B, T, self.config.n_query_groups, total_qkv, self.config.head_size)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             qkv_1: "bf16[1, 8192, 16, 4, 128][67108864, 8192, 512, 128, 1]cuda:0" = qkv.view(1, 8192, 16, 4, 128);  qkv = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:275 in forward, code: qkv = qkv.permute(0, 2, 3, 1, 4)  # (B, n_query_groups, total_qkv, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             qkv_2: "bf16[1, 16, 4, 8192, 128][67108864, 512, 128, 8192, 1]cuda:0" = qkv_1.permute(0, 2, 3, 1, 4);  qkv_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:278 in forward, code: q, k, v = qkv.split((q_per_kv, 1, 1), dim=2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             split = qkv_2.split((2, 1, 1), dim = 2);  qkv_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             q: "bf16[1, 16, 2, 8192, 128][67108864, 512, 128, 8192, 1]cuda:0" = split[0]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k: "bf16[1, 16, 1, 8192, 128][67108864, 512, 128, 8192, 1]cuda:0" = split[1]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             v: "bf16[1, 16, 1, 8192, 128][67108864, 512, 128, 8192, 1]cuda:0" = split[2];  split = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:284 in forward, code: k = k.expand(B, self.config.n_query_groups, q_per_kv, T, self.config.head_size)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k_1: "bf16[1, 16, 2, 8192, 128][67108864, 512, 0, 8192, 1]cuda:0" = k.expand(1, 16, 2, 8192, 128);  k = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:285 in forward, code: v = v.expand(B, self.config.n_query_groups, q_per_kv, T, self.config.head_size)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             v_1: "bf16[1, 16, 2, 8192, 128][67108864, 512, 0, 8192, 1]cuda:0" = v.expand(1, 16, 2, 8192, 128);  v = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:287 in forward, code: q = q.reshape(B, -1, T, self.config.head_size)  # (B, nh_q, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             q_1: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = q.reshape(1, -1, 8192, 128);  q = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:288 in forward, code: k = k.reshape(B, -1, T, self.config.head_size)  # (B, nh_k, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k_2: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = k_1.reshape(1, -1, 8192, 128);  k_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:289 in forward, code: v = v.reshape(B, -1, T, self.config.head_size)  # (B, nh_v, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             v_2: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = v_1.reshape(1, -1, 8192, 128);  v_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:291 in forward, code: q_roped = apply_rope(q[..., : self.config.rope_n_elem], cos, sin)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getitem_3: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = q_1[(Ellipsis, slice(None, 128, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:581 in apply_rope, code: x1 = x[..., : head_size // 2]  # (B, nh, T, hs/2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x1: "bf16[1, 32, 8192, 64][33554432, 1048576, 128, 1]cuda:0" = getitem_3[(Ellipsis, slice(None, 64, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:582 in apply_rope, code: x2 = x[..., head_size // 2 :]  # (B, nh, T, hs/2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x2: "bf16[1, 32, 8192, 64][33554432, 1048576, 128, 1]cuda:0" = getitem_3[(Ellipsis, slice(64, None, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:583 in apply_rope, code: rotated = torch.cat((-x2, x1), dim=-1)  # (B, nh, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             neg: "bf16[1, 32, 8192, 64][16777216, 524288, 64, 1]cuda:0" = -x2;  x2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rotated: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = torch.cat((neg, x1), dim = -1);  neg = x1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:588 in apply_rope, code: cos = cos.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             cos_1: "bf16[1, 8192, 128][1048576, 128, 1]cuda:0" = cos.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:589 in apply_rope, code: sin = sin.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             sin_1: "bf16[1, 8192, 128][1048576, 128, 1]cuda:0" = sin.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:591 in apply_rope, code: roped = (x * cos) + (rotated * sin)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_3: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = getitem_3 * cos_1;  getitem_3 = cos_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_4: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = rotated * sin_1;  rotated = sin_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             roped: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = mul_3 + mul_4;  mul_3 = mul_4 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:592 in apply_rope, code: return roped.to(dtype=x.dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             q_roped: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = roped.to(dtype = torch.bfloat16);  roped = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:292 in forward, code: k_roped = apply_rope(k[..., : self.config.rope_n_elem], cos, sin)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getitem_6: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = k_2[(Ellipsis, slice(None, 128, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:581 in apply_rope, code: x1 = x[..., : head_size // 2]  # (B, nh, T, hs/2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x1_1: "bf16[1, 32, 8192, 64][33554432, 1048576, 128, 1]cuda:0" = getitem_6[(Ellipsis, slice(None, 64, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:582 in apply_rope, code: x2 = x[..., head_size // 2 :]  # (B, nh, T, hs/2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x2_1: "bf16[1, 32, 8192, 64][33554432, 1048576, 128, 1]cuda:0" = getitem_6[(Ellipsis, slice(64, None, None))]
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:583 in apply_rope, code: rotated = torch.cat((-x2, x1), dim=-1)  # (B, nh, T, hs)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             neg_1: "bf16[1, 32, 8192, 64][16777216, 524288, 64, 1]cuda:0" = -x2_1;  x2_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rotated_1: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = torch.cat((neg_1, x1_1), dim = -1);  neg_1 = x1_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:588 in apply_rope, code: cos = cos.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             cos_2: "bf16[1, 8192, 128][1048576, 128, 1]cuda:0" = cos.unsqueeze(-3);  cos = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:589 in apply_rope, code: sin = sin.unsqueeze(-3)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             sin_2: "bf16[1, 8192, 128][1048576, 128, 1]cuda:0" = sin.unsqueeze(-3);  sin = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:591 in apply_rope, code: roped = (x * cos) + (rotated * sin)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_5: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = getitem_6 * cos_2;  getitem_6 = cos_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_6: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = rotated_1 * sin_2;  rotated_1 = sin_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             roped_1: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = mul_5 + mul_6;  mul_5 = mul_6 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:592 in apply_rope, code: return roped.to(dtype=x.dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k_roped: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = roped_1.to(dtype = torch.bfloat16);  roped_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:293 in forward, code: q = torch.cat((q_roped, q[..., self.config.rope_n_elem :]), dim=-1)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getitem_9: "bf16[1, 32, 8192, 0][33554432, 1048576, 128, 1]cuda:0" = q_1[(Ellipsis, slice(128, None, None))];  q_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             q_2: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = torch.cat((q_roped, getitem_9), dim = -1);  q_roped = getitem_9 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:294 in forward, code: k = torch.cat((k_roped, k[..., self.config.rope_n_elem :]), dim=-1)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getitem_10: "bf16[1, 32, 8192, 0][33554432, 1048576, 128, 1]cuda:0" = k_2[(Ellipsis, slice(128, None, None))];  k_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             k_3: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = torch.cat((k_roped, getitem_10), dim = -1);  k_roped = getitem_10 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:334 in scaled_dot_product_attention, code: scores = q @ k.mT * scale
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             getattr_1: "bf16[1, 32, 128, 8192][33554432, 1048576, 1, 128]cuda:0" = k_3.mT;  k_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             matmul: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = q_2 @ getattr_1;  q_2 = getattr_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             scores: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = matmul * 0.08333333333333333;  matmul = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:336 in scaled_dot_product_attention, code: torch.tanh(scores / self.config.attention_logit_softcapping) * self.config.attention_logit_softcapping
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             truediv: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = scores / 50.0;  scores = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             tanh: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = torch.tanh(truediv);  truediv = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             scores_1: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = tanh * 50.0;  tanh = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:339 in scaled_dot_product_attention, code: mask = torch.ones(q.size(2), q.size(2), dtype=q.dtype, device=q.device).triu(diagonal=1)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             ones: "bf16[8192, 8192][8192, 1]cuda:0" = torch.ones(8192, 8192, dtype = torch.bfloat16, device = device(type='cuda', index=0))
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mask: "bf16[8192, 8192][8192, 1]cuda:0" = ones.triu(diagonal = 1);  ones = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:340 in scaled_dot_product_attention, code: mask.masked_fill_(mask.bool(), torch.finfo(q.dtype).min)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             bool_1: "b8[8192, 8192][8192, 1]cuda:0" = mask.bool()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             masked_fill_: "bf16[8192, 8192][8192, 1]cuda:0" = mask.masked_fill_(bool_1, -3.3895313892515355e+38);  bool_1 = masked_fill_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:341 in scaled_dot_product_attention, code: scores = scores + mask
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             scores_2: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = scores_1 + mask;  scores_1 = mask = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:342 in scaled_dot_product_attention, code: scores = torch.nn.functional.softmax(scores, dim=-1, dtype=torch.float).to(dtype=q.dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             softmax: "f32[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = torch.nn.functional.softmax(scores_2, dim = -1, dtype = torch.float32);  scores_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             scores_3: "bf16[1, 32, 8192, 8192][2147483648, 67108864, 8192, 1]cuda:0" = softmax.to(dtype = torch.bfloat16);  softmax = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:343 in scaled_dot_product_attention, code: y = scores @ v
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             y: "bf16[1, 32, 8192, 128][33554432, 1048576, 128, 1]cuda:0" = scores_3 @ v_2;  scores_3 = v_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:348 in scaled_dot_product_attention, code: return y.transpose(1, 2)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             y_1: "bf16[1, 8192, 32, 128][33554432, 128, 1048576, 1]cuda:0" = y.transpose(1, 2);  y = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:321 in forward, code: y = y.reshape(B, T, self.config.head_size * self.config.n_head)  # re-assemble all head outputs side by side
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             y_2: "bf16[1, 8192, 4096][33554432, 4096, 1]cuda:0" = y_1.reshape(1, 8192, 4096);  y_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:324 in forward, code: return self.proj(y)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             attention_output: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = torch._C._nn.linear(y_2, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_, None);  y_2 = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_attn_modules_proj_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_3: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = attention_output.float();  attention_output = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_9: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_3 * x_3
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             norm_x_1: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul_9, dim = -1, keepdim = True);  mul_9 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             add_5: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x_1 + 1e-05;  norm_x_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rsqrt_1: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add_5);  add_5 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed_2: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_3 * rsqrt_1;  x_3 = rsqrt_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             weight_1: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_;  l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_attention_norm_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             float_4: "f32[2][1]cuda:0" = weight_1.float();  weight_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_11: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed_2 * float_4;  x_normed_2 = float_4 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             attention_output_1: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_11.to(dtype = torch.bfloat16);  mul_11 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:236 in forward, code: x = attention_output + x
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_4: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = attention_output_1 + x_2;  attention_output_1 = x_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_5: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_4.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_12: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_5 * x_5
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             norm_x_2: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul_12, dim = -1, keepdim = True);  mul_12 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             add_8: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x_2 + 1e-05;  norm_x_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rsqrt_2: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add_8);  add_8 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed_3: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_5 * rsqrt_2;  x_5 = rsqrt_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             weight_2: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_;  l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_norm_2_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             float_6: "f32[2][1]cuda:0" = weight_2.float();  weight_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_14: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed_3 * float_6;  x_normed_3 = float_6 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             to_5: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_14.to(dtype = torch.bfloat16);  mul_14 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:406 in forward, code: x_fc_1 = self.fc_1(x)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_fc_1: "bf16[1, 8192, 16][131072, 16, 1]cuda:0" = torch._C._nn.linear(to_5, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_, None);  l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_1_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:407 in forward, code: x_fc_2 = self.fc_2(x)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_fc_2: "bf16[1, 8192, 16][131072, 16, 1]cuda:0" = torch._C._nn.linear(to_5, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_, None);  to_5 = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_fc_2_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:408 in forward, code: x = torch.nn.functional.gelu(x_fc_1, approximate=self.config.gelu_approximate) * x_fc_2
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             gelu: "bf16[1, 8192, 16][131072, 16, 1]cuda:0" = torch._C._nn.gelu(x_fc_1, approximate = 'tanh');  x_fc_1 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_6: "bf16[1, 8192, 16][131072, 16, 1]cuda:0" = gelu * x_fc_2;  gelu = x_fc_2 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:409 in forward, code: return self.proj(x)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             linear_4: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = torch._C._nn.linear(x_6, l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_, None);  x_6 = l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_mlp_modules_proj_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:643 in forward, code: x = x.float()
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_7: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = linear_4.float();  linear_4 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:645 in forward, code: norm_x = torch.mean(x * x, dim=self.dim, keepdim=True)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_16: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_7 * x_7
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             norm_x_3: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.mean(mul_16, dim = -1, keepdim = True);  mul_16 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:646 in forward, code: x_normed = x * torch.rsqrt(norm_x + self.eps)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             add_10: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = norm_x_3 + 1e-05;  norm_x_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             rsqrt_3: "f32[1, 8192, 1][8192, 1, 1]cuda:0" = torch.rsqrt(add_10);  add_10 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_normed_4: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_7 * rsqrt_3;  x_7 = rsqrt_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:647 in forward, code: weight = (1 + self.weight) if self.add_unit_offset else self.weight
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             weight_3: "bf16[2][1]cuda:0" = 1 + l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_;  l_self_modules_transformer_modules_h_modules_1_modules_checkpoint_wrapped_module_modules_post_mlp_norm_parameters_weight_ = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:648 in forward, code: return (x_normed * weight.float()).to(dtype=dtype)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             float_8: "f32[2][1]cuda:0" = weight_3.float();  weight_3 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             mul_18: "f32[1, 8192, 2][16384, 2, 1]cuda:0" = x_normed_4 * float_8;  x_normed_4 = float_8 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             to_6: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = mul_18.to(dtype = torch.bfloat16);  mul_18 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]              # File: /usr/local/lib/python3.12/dist-packages/litgpt/model.py:237 in forward, code: x = self.post_mlp_norm(self.mlp(self.norm_2(x))) + x
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             x_8: "bf16[1, 8192, 2][16384, 2, 1]cuda:0" = to_6 + x_4;  to_6 = x_4 = None
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             return (x_8,)
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code]             
V0914 01:48:02.180000 112965 torch/_dynamo/output_graph.py:1680] [0/0] [__graph_code] 
/usr/local/lib/python3.12/dist-packages/torch/__init__.py:1124: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead
  return isinstance(obj, torch.Tensor)
I0914 01:48:06.298000 112965 torch/_inductor/remote_cache.py:422] Cache Metrics: None
I0914 01:48:06.298000 112965 torch/_inductor/remote_cache.py:422] 
